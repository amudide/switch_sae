{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relu = pd.read_csv(\"primary-relu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relu = df_relu[df_relu['State'] == 'finished']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Notes</th>\n",
       "      <th>User</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Created</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Sweep</th>\n",
       "      <th>StandardTrainerNew_Anthropic-0.activation_dim</th>\n",
       "      <th>StandardTrainerNew_Anthropic-0.decay_start</th>\n",
       "      <th>...</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/l1_loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/l1_penalty</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/l2_loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/l2_ratio</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/loss_original</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/loss_reconstructed</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/loss_zero</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/mse_loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/sparsity_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rose-microwave-9</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-10T03:17:36.000Z</td>\n",
       "      <td>11652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>24000</td>\n",
       "      <td>...</td>\n",
       "      <td>134.745834</td>\n",
       "      <td>30.00</td>\n",
       "      <td>49.454788</td>\n",
       "      <td>0.764901</td>\n",
       "      <td>6669.611328</td>\n",
       "      <td>3.334572</td>\n",
       "      <td>3.870035</td>\n",
       "      <td>17.336954</td>\n",
       "      <td>2556.323730</td>\n",
       "      <td>137.109589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lunar-bush-8</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-10T03:17:10.000Z</td>\n",
       "      <td>11690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>24000</td>\n",
       "      <td>...</td>\n",
       "      <td>159.295456</td>\n",
       "      <td>17.98</td>\n",
       "      <td>43.404381</td>\n",
       "      <td>0.829841</td>\n",
       "      <td>4889.353027</td>\n",
       "      <td>3.334572</td>\n",
       "      <td>3.688919</td>\n",
       "      <td>17.336954</td>\n",
       "      <td>1984.641357</td>\n",
       "      <td>161.552383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confused-monkey-7</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-10T03:16:57.000Z</td>\n",
       "      <td>11542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>24000</td>\n",
       "      <td>...</td>\n",
       "      <td>189.246063</td>\n",
       "      <td>10.78</td>\n",
       "      <td>38.765923</td>\n",
       "      <td>0.873256</td>\n",
       "      <td>3647.064453</td>\n",
       "      <td>3.334572</td>\n",
       "      <td>3.564746</td>\n",
       "      <td>17.336954</td>\n",
       "      <td>1581.077148</td>\n",
       "      <td>191.650040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>azure-yogurt-6</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-10T03:16:19.000Z</td>\n",
       "      <td>11656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>24000</td>\n",
       "      <td>...</td>\n",
       "      <td>231.828552</td>\n",
       "      <td>6.46</td>\n",
       "      <td>34.592636</td>\n",
       "      <td>0.903345</td>\n",
       "      <td>2770.890381</td>\n",
       "      <td>3.334572</td>\n",
       "      <td>3.485929</td>\n",
       "      <td>17.336954</td>\n",
       "      <td>1256.385742</td>\n",
       "      <td>234.443436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name     State Notes  User  Tags                   Created  \\\n",
       "0   rose-microwave-9  finished     -   NaN   NaN  2024-07-10T03:17:36.000Z   \n",
       "1       lunar-bush-8  finished     -   NaN   NaN  2024-07-10T03:17:10.000Z   \n",
       "2  confused-monkey-7  finished     -   NaN   NaN  2024-07-10T03:16:57.000Z   \n",
       "3     azure-yogurt-6  finished     -   NaN   NaN  2024-07-10T03:16:19.000Z   \n",
       "\n",
       "   Runtime  Sweep  StandardTrainerNew_Anthropic-0.activation_dim  \\\n",
       "0    11652    NaN                                            768   \n",
       "1    11690    NaN                                            768   \n",
       "2    11542    NaN                                            768   \n",
       "3    11656    NaN                                            768   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-0.decay_start  ...  \\\n",
       "0                                       24000  ...   \n",
       "1                                       24000  ...   \n",
       "2                                       24000  ...   \n",
       "3                                       24000  ...   \n",
       "\n",
       "  StandardTrainerNew_Anthropic-1/l1_loss  \\\n",
       "0                             134.745834   \n",
       "1                             159.295456   \n",
       "2                             189.246063   \n",
       "3                             231.828552   \n",
       "\n",
       "  StandardTrainerNew_Anthropic-1/l1_penalty  \\\n",
       "0                                     30.00   \n",
       "1                                     17.98   \n",
       "2                                     10.78   \n",
       "3                                      6.46   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/l2_loss  \\\n",
       "0                               49.454788   \n",
       "1                               43.404381   \n",
       "2                               38.765923   \n",
       "3                               34.592636   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/l2_ratio  \\\n",
       "0                                 0.764901   \n",
       "1                                 0.829841   \n",
       "2                                 0.873256   \n",
       "3                                 0.903345   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/loss  \\\n",
       "0                          6669.611328   \n",
       "1                          4889.353027   \n",
       "2                          3647.064453   \n",
       "3                          2770.890381   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/loss_original  \\\n",
       "0                                      3.334572   \n",
       "1                                      3.334572   \n",
       "2                                      3.334572   \n",
       "3                                      3.334572   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/loss_reconstructed  \\\n",
       "0                                           3.870035   \n",
       "1                                           3.688919   \n",
       "2                                           3.564746   \n",
       "3                                           3.485929   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/loss_zero  \\\n",
       "0                                 17.336954   \n",
       "1                                 17.336954   \n",
       "2                                 17.336954   \n",
       "3                                 17.336954   \n",
       "\n",
       "  StandardTrainerNew_Anthropic-1/mse_loss  \\\n",
       "0                             2556.323730   \n",
       "1                             1984.641357   \n",
       "2                             1581.077148   \n",
       "3                             1256.385742   \n",
       "\n",
       "  StandardTrainerNew_Anthropic-1/sparsity_loss  \n",
       "0                                   137.109589  \n",
       "1                                   161.552383  \n",
       "2                                   191.650040  \n",
       "3                                   234.443436  \n",
       "\n",
       "[4 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'State', 'Notes', 'User', 'Tags', 'Created', 'Runtime', 'Sweep',\n",
      "       'StandardTrainerNew_Anthropic-0.activation_dim',\n",
      "       'StandardTrainerNew_Anthropic-0.decay_start',\n",
      "       'StandardTrainerNew_Anthropic-0.device',\n",
      "       'StandardTrainerNew_Anthropic-0.dict_class',\n",
      "       'StandardTrainerNew_Anthropic-0.dict_size',\n",
      "       'StandardTrainerNew_Anthropic-0.l1_penalty',\n",
      "       'StandardTrainerNew_Anthropic-0.lambda_warm_steps',\n",
      "       'StandardTrainerNew_Anthropic-0.lr',\n",
      "       'StandardTrainerNew_Anthropic-0.seed',\n",
      "       'StandardTrainerNew_Anthropic-0.steps',\n",
      "       'StandardTrainerNew_Anthropic-0.trainer',\n",
      "       'StandardTrainerNew_Anthropic-0.wandb_name',\n",
      "       'StandardTrainerNew_Anthropic-1.activation_dim',\n",
      "       'StandardTrainerNew_Anthropic-1.decay_start',\n",
      "       'StandardTrainerNew_Anthropic-1.device',\n",
      "       'StandardTrainerNew_Anthropic-1.dict_class',\n",
      "       'StandardTrainerNew_Anthropic-1.dict_size',\n",
      "       'StandardTrainerNew_Anthropic-1.l1_penalty',\n",
      "       'StandardTrainerNew_Anthropic-1.lambda_warm_steps',\n",
      "       'StandardTrainerNew_Anthropic-1.lr',\n",
      "       'StandardTrainerNew_Anthropic-1.seed',\n",
      "       'StandardTrainerNew_Anthropic-1.steps',\n",
      "       'StandardTrainerNew_Anthropic-1.trainer',\n",
      "       'StandardTrainerNew_Anthropic-1.wandb_name',\n",
      "       'StandardTrainerNew_Anthropic-0/cossim',\n",
      "       'StandardTrainerNew_Anthropic-0/frac_alive',\n",
      "       'StandardTrainerNew_Anthropic-0/frac_recovered',\n",
      "       'StandardTrainerNew_Anthropic-0/frac_variance_explained',\n",
      "       'StandardTrainerNew_Anthropic-0/l0',\n",
      "       'StandardTrainerNew_Anthropic-0/l1_loss',\n",
      "       'StandardTrainerNew_Anthropic-0/l1_penalty',\n",
      "       'StandardTrainerNew_Anthropic-0/l2_loss',\n",
      "       'StandardTrainerNew_Anthropic-0/l2_ratio',\n",
      "       'StandardTrainerNew_Anthropic-0/loss',\n",
      "       'StandardTrainerNew_Anthropic-0/loss_original',\n",
      "       'StandardTrainerNew_Anthropic-0/loss_reconstructed',\n",
      "       'StandardTrainerNew_Anthropic-0/loss_zero',\n",
      "       'StandardTrainerNew_Anthropic-0/mse_loss',\n",
      "       'StandardTrainerNew_Anthropic-0/sparsity_loss',\n",
      "       'StandardTrainerNew_Anthropic-1/cossim',\n",
      "       'StandardTrainerNew_Anthropic-1/frac_alive',\n",
      "       'StandardTrainerNew_Anthropic-1/frac_recovered',\n",
      "       'StandardTrainerNew_Anthropic-1/frac_variance_explained',\n",
      "       'StandardTrainerNew_Anthropic-1/l0',\n",
      "       'StandardTrainerNew_Anthropic-1/l1_loss',\n",
      "       'StandardTrainerNew_Anthropic-1/l1_penalty',\n",
      "       'StandardTrainerNew_Anthropic-1/l2_loss',\n",
      "       'StandardTrainerNew_Anthropic-1/l2_ratio',\n",
      "       'StandardTrainerNew_Anthropic-1/loss',\n",
      "       'StandardTrainerNew_Anthropic-1/loss_original',\n",
      "       'StandardTrainerNew_Anthropic-1/loss_reconstructed',\n",
      "       'StandardTrainerNew_Anthropic-1/loss_zero',\n",
      "       'StandardTrainerNew_Anthropic-1/mse_loss',\n",
      "       'StandardTrainerNew_Anthropic-1/sparsity_loss'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_relu.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the patterns to match\n",
    "patterns = ['l0$', 'frac_recovered$', 'mse_loss$']\n",
    "\n",
    "# Use str.contains with regex to filter columns\n",
    "filtered_columns = df_relu.columns[df_relu.columns.str.contains('|'.join(patterns))]\n",
    "\n",
    "# Create a new DataFrame with only the filtered columns\n",
    "df_filtered = df_relu[filtered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StandardTrainerNew_Anthropic-0/frac_recovered',\n",
       "       'StandardTrainerNew_Anthropic-0/l0',\n",
       "       'StandardTrainerNew_Anthropic-0/mse_loss',\n",
       "       'StandardTrainerNew_Anthropic-1/frac_recovered',\n",
       "       'StandardTrainerNew_Anthropic-1/l0',\n",
       "       'StandardTrainerNew_Anthropic-1/mse_loss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group columns by type\n",
    "mse_loss_cols = [col for col in df_relu.columns if col.endswith('/mse_loss')]\n",
    "frac_recovered_cols = [col for col in df_relu.columns if col.endswith('/frac_recovered')]\n",
    "l0_cols = [col for col in df_relu.columns if col.endswith('/l0')]\n",
    "\n",
    "# Create new columns with the mean of each group\n",
    "df_relu['mse_loss_mean'] = df_relu[mse_loss_cols].mean(axis=1)\n",
    "df_relu['frac_recovered_mean'] = df_relu[frac_recovered_cols].mean(axis=1)\n",
    "df_relu['l0_mean'] = df_relu[l0_cols].mean(axis=1)\n",
    "\n",
    "# Keep only the new columns\n",
    "df_filtered = df_relu[['mse_loss_mean', 'frac_recovered_mean', 'l0_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group columns by type\n",
    "mse_loss_cols = [col for col in df_relu.columns if col.endswith('/mse_loss')]\n",
    "frac_recovered_cols = [col for col in df_relu.columns if col.endswith('/frac_recovered')]\n",
    "l0_cols = [col for col in df_relu.columns if col.endswith('/l0')]\n",
    "\n",
    "# Combine the lists in the desired order\n",
    "all_cols = mse_loss_cols + frac_recovered_cols + l0_cols\n",
    "\n",
    "# Create a new DataFrame with the columns in the grouped order\n",
    "df_filtered = df_relu[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandardTrainerNew_Anthropic-0/mse_loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/mse_loss</th>\n",
       "      <th>StandardTrainerNew_Anthropic-0/frac_recovered</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/frac_recovered</th>\n",
       "      <th>StandardTrainerNew_Anthropic-0/l0</th>\n",
       "      <th>StandardTrainerNew_Anthropic-1/l0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2240.635742</td>\n",
       "      <td>2556.323730</td>\n",
       "      <td>0.971492</td>\n",
       "      <td>0.961759</td>\n",
       "      <td>45.667480</td>\n",
       "      <td>43.908936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1766.588013</td>\n",
       "      <td>1984.641357</td>\n",
       "      <td>0.981300</td>\n",
       "      <td>0.974694</td>\n",
       "      <td>64.776733</td>\n",
       "      <td>55.123291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1414.602051</td>\n",
       "      <td>1581.077148</td>\n",
       "      <td>0.987501</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>107.998901</td>\n",
       "      <td>83.944824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1099.577393</td>\n",
       "      <td>1256.385742</td>\n",
       "      <td>0.992194</td>\n",
       "      <td>0.989191</td>\n",
       "      <td>205.311279</td>\n",
       "      <td>146.779785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StandardTrainerNew_Anthropic-0/mse_loss  \\\n",
       "0                              2240.635742   \n",
       "1                              1766.588013   \n",
       "2                              1414.602051   \n",
       "3                              1099.577393   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/mse_loss  \\\n",
       "0                              2556.323730   \n",
       "1                              1984.641357   \n",
       "2                              1581.077148   \n",
       "3                              1256.385742   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-0/frac_recovered  \\\n",
       "0                                       0.971492   \n",
       "1                                       0.981300   \n",
       "2                                       0.987501   \n",
       "3                                       0.992194   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-1/frac_recovered  \\\n",
       "0                                       0.961759   \n",
       "1                                       0.974694   \n",
       "2                                       0.983562   \n",
       "3                                       0.989191   \n",
       "\n",
       "   StandardTrainerNew_Anthropic-0/l0  StandardTrainerNew_Anthropic-1/l0  \n",
       "0                          45.667480                          43.908936  \n",
       "1                          64.776733                          55.123291  \n",
       "2                         107.998901                          83.944824  \n",
       "3                         205.311279                         146.779785  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m df_melted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_melted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_column\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Pivot the DataFrame to get the desired format\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m \u001b[43mdf_melted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Reset the index to make 'trainer' a regular column\u001b[39;00m\n\u001b[1;32m     29\u001b[0m df_combined\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\n\u001b[1;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:570\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    566\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindexed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    571\u001b[0m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    572\u001b[0m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m    573\u001b[0m ]\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/series.py:4615\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[0;34m(self, level, fill_value, sort)\u001b[0m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[1;32m   4572\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4611\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[1;32m   4612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4613\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[0;32m-> 4615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/reshape/reshape.py:517\u001b[0m, in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value, sort)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m--> 517\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_expanddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[1;32m    521\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/reshape/reshape.py:154\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[0;34m(self, index, level, constructor, sort)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[1;32m    147\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m         PerformanceWarning,\n\u001b[1;32m    151\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    152\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/cb/rsingh/miniconda3/envs/sae/lib/python3.9/site-packages/pandas/core/reshape/reshape.py:210\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# First, let's group the columns by type\n",
    "mse_loss_cols = [col for col in df_relu.columns if col.endswith('/mse_loss')]\n",
    "frac_recovered_cols = [col for col in df_relu.columns if col.endswith('/frac_recovered')]\n",
    "l0_cols = [col for col in df_relu.columns if col.endswith('/l0')]\n",
    "\n",
    "# Create a list of tuples with column names and their corresponding type\n",
    "column_types = [(col, 'mse_loss') for col in mse_loss_cols] + \\\n",
    "               [(col, 'frac_recovered') for col in frac_recovered_cols] + \\\n",
    "               [(col, 'l0') for col in l0_cols]\n",
    "\n",
    "# Melt the DataFrame\n",
    "df_melted = pd.melt(df_relu, \n",
    "                    value_vars=[col for col, _ in column_types],\n",
    "                    var_name='original_column',\n",
    "                    value_name='value')\n",
    "\n",
    "# Add a 'type' column based on the original column name\n",
    "df_melted['type'] = df_melted['original_column'].map(dict(column_types))\n",
    "\n",
    "# Extract the trainer name from the original column\n",
    "df_melted['trainer'] = df_melted['original_column'].str.split('/').str[0]\n",
    "\n",
    "# Instead of pivoting, we'll use groupby and unstack\n",
    "df_combined = df_melted.groupby(['trainer', 'type'])['value'].first().unstack()\n",
    "\n",
    "# Reset the index to make 'trainer' a regular column\n",
    "df_combined.reset_index(inplace=True)\n",
    "\n",
    "# Optionally, rename the columns to remove the top-level\n",
    "df_combined.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
